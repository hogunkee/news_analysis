{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding default loaded\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "from ThemeSeacher import Updator, clean, PhraserModel, tokenizer\n",
    "from ThemeSeacher import KeywordDict, Model, Extractor\n",
    "from ThemeSeacher import EmbeddingModel, Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phraser_default.bin  loaded\n",
      "keyword dictionary loaded\n"
     ]
    }
   ],
   "source": [
    "phraser = PhraserModel().get_phraser\n",
    "dic = KeywordDict(phraser=phraser).get_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open('obj/' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def exist(name):\n",
    "    return os.path.exists('obj/' + name + '.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding default loaded\n"
     ]
    }
   ],
   "source": [
    "embedding = EmbeddingModel().get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557440"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = load_obj('seq2seq_embed')\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, bs):\n",
    "    np.random.shuffle(data)\n",
    "    for i in range(len(data)//bs):\n",
    "        batch = data[bs*i: bs*(i+1)]\n",
    "\n",
    "        x_gen = list(map(lambda k: np.pad(k, \\\n",
    "                ((40-len(k),0),(0,0)),'constant'), batch))\n",
    "        mask_gen = list(map(lambda k: np.array(\\\n",
    "                [0 for i in range(40-len(k))] + \\\n",
    "                [1 for j in range(len(k))]), batch))\n",
    "\n",
    "        yield np.array(list(x_gen)), np.array(list(mask_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mixmodel(object):\n",
    "    def __init__(self, n_z=4, sigma=1e-3, lr=1e-4, alpha=1, beta=1):\n",
    "        title_len = 40\n",
    "        em_dim = 100\n",
    "        hidden_dim = 100\n",
    "        \n",
    "        self.n_z = n_z\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.sigma = sigma\n",
    "    \n",
    "        self.x = tf.placeholder(tf.float32, [None, title_len, em_dim])\n",
    "        self.mask = tf.placeholder(tf.float32, [None, title_len])\n",
    "    \n",
    "        ### Seq2seq Encoder ###\n",
    "        encoder_cell = tf.contrib.rnn.LSTMCell(hidden_dim)\n",
    "        encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "            encoder_cell, self.x,\n",
    "            dtype=tf.float32, time_major=False,\n",
    "        )\n",
    "\n",
    "        self.sentence_embed = encoder_final_state[1]\n",
    "        \n",
    "        ### VAE Encoder ###\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(self.sentence_embed, 100, scope='enc_fc1', activation_fn=tf.nn.elu)\n",
    "        f2 = fc(f1, 64, scope='enc_fc2', activation_fn=tf.nn.elu)\n",
    "        f3 = fc(f2, 64, scope='enc_fc3', activation_fn=tf.nn.elu)\n",
    "        f4 = fc(f3, 32, scope='enc_fc4', activation_fn=tf.nn.elu)\n",
    "        f5 = fc(f4, 32, scope='enc_fc5', activation_fn=tf.nn.elu)\n",
    "        f6 = fc(f5, 16, scope='enc_fc6', activation_fn=tf.nn.elu)\n",
    "        f7 = fc(f6, 16, scope='enc_fc7', activation_fn=tf.nn.elu)\n",
    "        f8 = fc(f7, 8, scope='enc_fc8', activation_fn=tf.nn.elu)\n",
    "        f9 = fc(f8, 8, scope='enc_fc9', activation_fn=tf.nn.elu)\n",
    "        f10 = fc(f9, 4, scope='enc_fc10', activation_fn=tf.nn.elu)\n",
    "        self.z_mu = fc(f10, self.n_z, scope='enc_fc11_mu', activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f10, self.n_z, scope='enc_fc11_sigma', activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),\n",
    "                               mean=0, stddev=self.sigma, dtype=tf.float32)\n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "\n",
    "        ### VAE Decoder ###\n",
    "        # z -> x_hat\n",
    "        g1 = fc(self.z, 4, scope='dec_fc1', activation_fn=tf.nn.elu)\n",
    "        g2 = fc(g1, 8, scope='dec_fc2', activation_fn=tf.nn.elu)\n",
    "        g3 = fc(g2, 8, scope='dec_fc3', activation_fn=tf.nn.elu)\n",
    "        g4 = fc(g3, 16, scope='dec_fc4', activation_fn=tf.nn.elu)\n",
    "        g5 = fc(g4, 16, scope='dec_fc5', activation_fn=tf.nn.elu)\n",
    "        g6 = fc(g5, 32, scope='dec_fc6', activation_fn=tf.nn.elu)\n",
    "        g7 = fc(g6, 32, scope='dec_fc7', activation_fn=tf.nn.elu)\n",
    "        g8 = fc(g7, 64, scope='dec_fc8', activation_fn=tf.nn.elu)\n",
    "        g9 = fc(g8, 64, scope='dec_fc9', activation_fn=tf.nn.elu)\n",
    "        g10 = fc(g9, 100, scope='dec_fc10', activation_fn=tf.nn.elu)\n",
    "        self.sentence_embed_hat = fc(g10, 100, scope='dec_fc11', activation_fn=None)\n",
    "\n",
    "        ### Seq2seq Decoder ###\n",
    "        s_code = tf.reshape(self.sentence_embed_hat, [-1, 1, hidden_dim])\n",
    "        decoder_cell = tf.contrib.rnn.LSTMCell(em_dim)\n",
    "        decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "            decoder_cell, tf.tile(s_code, [1, title_len, 1]),\n",
    "            initial_state = encoder_final_state,\n",
    "            dtype=tf.float32, time_major=False, scope=\"plain_decoder\",\n",
    "        )\n",
    "\n",
    "        x_ = tf.reverse(decoder_outputs, [1])\n",
    "        # Reconstruction loss\n",
    "        self.embed_loss = self.alpha * tf.reduce_mean(tf.squared_difference(self.sentence_embed, self.sentence_embed_hat))\n",
    "        \n",
    "        l2_loss = tf.reduce_mean(tf.squared_difference(self.x, x_), axis=2)\n",
    "        self.recon_loss = tf.reduce_mean(l2_loss * self.mask)\n",
    "        \n",
    "        # Latent loss\n",
    "        # Kullback Leibler divergence: measure the difference between two distributions\n",
    "        # Here we measure the divergence between the latent distribution and N(0, 1)\n",
    "        latent_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        self.latent_loss = self.beta * tf.reduce_mean(latent_loss)\n",
    "        \n",
    "        self.loss = self.embed_loss + self.recon_loss + self.latent_loss\n",
    "        self.train = tf.train.AdamOptimizer(learning_rate=lr).minimize(self.loss)\n",
    "        self.output = x_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "model = mixmodel(n_z=4, sigma=1e-3, lr=1e-3, alpha=10, beta=10)\n",
    "\n",
    "tfconfig = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "sess=tf.Session(config=tfconfig)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/mixmodel_100.ckpt\n"
     ]
    }
   ],
   "source": [
    "model_name = 'mixmodel_100'\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, './ckpt/%s.ckpt' %model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100]\n",
      "steps: 100 / total loss: 0.0447, embed: 0.0196, recon: 0.0156, latent: 0.0095\n",
      "steps: 200 / total loss: 0.0330, embed: 0.0131, recon: 0.0151, latent: 0.0048\n",
      "steps: 300 / total loss: 0.0281, embed: 0.0100, recon: 0.0149, latent: 0.0032\n",
      "steps: 400 / total loss: 0.0253, embed: 0.0081, recon: 0.0147, latent: 0.0024\n",
      "steps: 500 / total loss: 0.0235, embed: 0.0069, recon: 0.0146, latent: 0.0020\n",
      "Epoch: [2/100]\n",
      "steps: 100 / total loss: 0.0154, embed: 0.0012, recon: 0.0142, latent: 0.0000\n",
      "steps: 200 / total loss: 0.0153, embed: 0.0011, recon: 0.0142, latent: 0.0000\n",
      "steps: 300 / total loss: 0.0152, embed: 0.0010, recon: 0.0142, latent: 0.0000\n",
      "steps: 400 / total loss: 0.0151, embed: 0.0009, recon: 0.0141, latent: 0.0000\n",
      "steps: 500 / total loss: 0.0150, embed: 0.0009, recon: 0.0141, latent: 0.0000\n",
      "Epoch: [3/100]\n",
      "steps: 100 / total loss: 0.0145, embed: 0.0005, recon: 0.0140, latent: 0.0000\n",
      "steps: 200 / total loss: 0.0144, embed: 0.0005, recon: 0.0139, latent: 0.0000\n",
      "steps: 300 / total loss: 0.0144, embed: 0.0004, recon: 0.0139, latent: 0.0000\n",
      "steps: 400 / total loss: 0.0143, embed: 0.0004, recon: 0.0139, latent: 0.0000\n",
      "steps: 500 / total loss: 0.0143, embed: 0.0004, recon: 0.0139, latent: 0.0000\n",
      "Epoch: [4/100]\n",
      "steps: 100 / total loss: 0.0140, embed: 0.0003, recon: 0.0137, latent: 0.0000\n",
      "steps: 200 / total loss: 0.0140, embed: 0.0003, recon: 0.0137, latent: 0.0000\n",
      "steps: 300 / total loss: 0.0140, embed: 0.0002, recon: 0.0137, latent: 0.0000\n",
      "steps: 400 / total loss: 0.0139, embed: 0.0002, recon: 0.0137, latent: 0.0000\n",
      "steps: 500 / total loss: 0.0139, embed: 0.0002, recon: 0.0137, latent: 0.0000\n",
      "Epoch: [5/100]\n",
      "steps: 100 / total loss: 0.0137, embed: 0.0002, recon: 0.0135, latent: 0.0000\n",
      "steps: 200 / total loss: 0.0137, embed: 0.0001, recon: 0.0135, latent: 0.0000\n",
      "steps: 300 / total loss: 0.0137, embed: 0.0001, recon: 0.0135, latent: 0.0000\n",
      "steps: 400 / total loss: 0.0136, embed: 0.0001, recon: 0.0135, latent: 0.0000\n",
      "steps: 500 / total loss: 0.0136, embed: 0.0001, recon: 0.0135, latent: 0.0000\n",
      "Epoch: [6/100]\n",
      "steps: 100 / total loss: 0.0135, embed: 0.0001, recon: 0.0134, latent: 0.0000\n",
      "steps: 200 / total loss: 0.0135, embed: 0.0001, recon: 0.0134, latent: 0.0000\n",
      "steps: 300 / total loss: 0.0134, embed: 0.0001, recon: 0.0134, latent: 0.0000\n",
      "steps: 400 / total loss: 0.0134, embed: 0.0001, recon: 0.0133, latent: 0.0000\n",
      "steps: 500 / total loss: 0.0134, embed: 0.0001, recon: 0.0133, latent: 0.0000\n",
      "Epoch: [7/100]\n",
      "steps: 100 / total loss: 0.0133, embed: 0.0001, recon: 0.0133, latent: 0.0000\n",
      "steps: 200 / total loss: 0.0133, embed: 0.0001, recon: 0.0132, latent: 0.0000\n",
      "steps: 300 / total loss: 0.0133, embed: 0.0001, recon: 0.0132, latent: 0.0000\n",
      "steps: 400 / total loss: 0.0132, embed: 0.0001, recon: 0.0132, latent: 0.0000\n",
      "steps: 500 / total loss: 0.0132, embed: 0.0000, recon: 0.0132, latent: 0.0000\n",
      "Epoch: [8/100]\n",
      "steps: 100 / total loss: 0.0132, embed: 0.0000, recon: 0.0131, latent: 0.0000\n",
      "steps: 200 / total loss: 0.0131, embed: 0.0000, recon: 0.0130, latent: 0.0000\n"
     ]
    }
   ],
   "source": [
    "bs=1000\n",
    "num_steps=len(train_data)//bs\n",
    "ne=100\n",
    "print_step=100\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=20)\n",
    "\n",
    "for epoch in range(ne):\n",
    "    print('Epoch: [%d/%d]' %(epoch+1, ne))\n",
    "    count = 0\n",
    "    avg_loss = 0\n",
    "    avg_embed_loss = 0\n",
    "    avg_recon_loss = 0\n",
    "    avg_latent_loss = 0\n",
    "    \n",
    "    for batch in generator(train_data, bs):\n",
    "        loss, e_loss, r_loss, l_loss , _ = sess.run([model.loss, \\\n",
    "                model.embed_loss, model.recon_loss, model.latent_loss, model.train], \\\n",
    "                feed_dict={model.x: batch[0], model.mask: batch[1]})\n",
    "        \n",
    "        avg_loss += loss\n",
    "        avg_embed_loss += e_loss\n",
    "        avg_recon_loss += r_loss\n",
    "        avg_latent_loss += l_loss\n",
    "        \n",
    "        count += 1\n",
    "        if count%print_step==0:\n",
    "            print('steps: %d / total loss: %.4f, embed: %.4f, recon: %.4f, latent: %.4f'\\\n",
    "                 %(count, avg_loss/count, avg_embed_loss/count, avg_recon_loss/count, avg_latent_loss/count))\n",
    "    \n",
    "\n",
    "    saver.save(sess, './ckpt/mixmodel_%d.ckpt'%(epoch+1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq2seq(word_list, model):\n",
    "    title = [x for x in word_list if len(x)!=1]\n",
    "    embed = embedding[title]\n",
    "    x = np.pad(embed, ((40-len(embed),0), (0,0)), 'constant')\n",
    "    mask = np.array([0 for i in range(40-len(embed))] + [1 for i in range(len(embed))])\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    output = sess.run(model.output, feed_dict={model.x: [np.array(list(x))], \\\n",
    "                       model.mask: [np.array(list(mask))]})\n",
    "    \n",
    "    return output[0][-len(embed):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = load_obj('upper1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "test_s2s = generate_seq2seq(top_news.lemmatized[index], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pakistan', 'gunman', 'stop', 'van', 'contain', 'teacher', 'educate', 'girl', 'shoot', 'murder', 'teacher', 'aid', 'worker']\n"
     ]
    }
   ],
   "source": [
    "print(top_news.lemmatized[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pakistan\n",
      "[('muslim', 0.8651015758514404), ('islamic', 0.8599182367324829), ('islamic_state', 0.8355435729026794), ('destroy_islamic', 0.8350486755371094), ('palestinian_terrorist', 0.8328242301940918), ('muslim_terrorist', 0.8267549276351929), ('iraqi_christian', 0.8197015523910522), ('terrorist', 0.8189867734909058), ('pakistan', 0.818328857421875), ('clash_islamic', 0.817404568195343)]\n",
      "\n",
      "gunman\n",
      "[('muslim', 0.8996880054473877), ('islamic', 0.8845473527908325), ('terrorist', 0.8711717128753662), ('islamic_terrorist', 0.8686994910240173), ('muslim_christian', 0.8685338497161865), ('muslim_terrorist', 0.8658732771873474), ('jihad', 0.8640064001083374), ('palestinian_terrorist', 0.8613203167915344), ('violent_jihad', 0.8603305220603943), ('islamic_state', 0.8594715595245361)]\n",
      "\n",
      "stop\n",
      "[('policeman', 0.8216572999954224), ('murder', 0.8203737139701843), ('kill', 0.8120800256729126), ('protest', 0.8115200996398926), ('polouse', 0.8014346957206726), ('arrest', 0.7997252941131592), ('christian', 0.7944931387901306), ('protester', 0.7850906848907471), ('soldier', 0.7830135822296143), ('jihad', 0.7829692959785461)]\n",
      "\n",
      "van\n",
      "[('policeman', 0.8496353030204773), ('murder', 0.83988356590271), ('christian', 0.821150541305542), ('kill', 0.8170445561408997), ('protest', 0.8159853219985962), ('polouse', 0.8151535987854004), ('innocent', 0.813666820526123), ('soldier', 0.8078024387359619), ('imprison', 0.8057783842086792), ('arrest', 0.800022304058075)]\n",
      "\n",
      "contain\n",
      "[('instance', 0.7503212690353394), ('also', 0.7460862398147583), ('many', 0.7249597907066345), ('rather', 0.7116436958312988), ('bring', 0.7036168575286865), ('thousand', 0.6869615912437439), ('part', 0.6775317192077637), ('spend', 0.675993025302887), ('back', 0.6745457053184509), ('fewer', 0.6742902994155884)]\n",
      "\n",
      "teacher\n",
      "[('innocent', 0.8275201320648193), ('schoolgirl', 0.8256834745407104), ('policeman', 0.8255434036254883), ('rape', 0.8243821263313293), ('christian', 0.8225758075714111), ('man_rape', 0.8166483044624329), ('murder', 0.8117443323135376), ('young_man', 0.8110255599021912), ('convict_murderer', 0.8047764301300049), ('manslaughter', 0.8020479083061218)]\n",
      "\n",
      "educate\n",
      "[('black', 0.8238430023193359), ('husband', 0.807439386844635), ('young_man', 0.8063780069351196), ('teenage_daughter', 0.8041098117828369), ('man', 0.8016436100006104), ('wife', 0.8001325726509094), ('father', 0.796324610710144), ('kid', 0.7927603721618652), ('taught', 0.7906257510185242), ('mother', 0.7878750562667847)]\n",
      "\n",
      "girl\n",
      "[('innocent', 0.827552080154419), ('rape', 0.825003445148468), ('young_man', 0.8237241506576538), ('policeman', 0.8213348388671875), ('self_righteously', 0.8171333074569702), ('church', 0.8159024715423584), ('schoolgirl', 0.8155454397201538), ('jesus_christ', 0.8145452737808228), ('christian', 0.8124856948852539), ('man_rape', 0.8118265867233276)]\n",
      "\n",
      "shoot\n",
      "[('man', 0.8200968503952026), ('father', 0.8026173114776611), ('mother', 0.799467146396637), ('black', 0.7794490456581116), ('young_man', 0.7702317237854004), ('teacher', 0.7619128823280334), ('teenage_daughter', 0.759680986404419), ('kill', 0.7483235597610474), ('young', 0.7478718757629395), ('husband', 0.7477287650108337)]\n",
      "\n",
      "murder\n",
      "[('murder', 0.8599502444267273), ('innocent', 0.8584936261177063), ('policeman', 0.8545147180557251), ('self_righteously', 0.8385637998580933), ('muslim', 0.8303725123405457), ('imprison', 0.8274356722831726), ('soldier', 0.827272355556488), ('kill', 0.8243327140808105), ('thug', 0.8243224620819092), ('gang_violence', 0.8224234580993652)]\n",
      "\n",
      "teacher\n",
      "[('teacher', 0.8211790919303894), ('self_righteously', 0.8110313415527344), ('child', 0.8080971240997314), ('latino_immigrant', 0.7970572113990784), ('innocent', 0.7970350980758667), ('young_man', 0.7959503531455994), ('student', 0.794463574886322), ('snobbery', 0.7917402386665344), ('mother', 0.7917028665542603), ('policeman', 0.7904702425003052)]\n",
      "\n",
      "aid\n",
      "[('also', 0.7897555828094482), ('instance', 0.6965511441230774), ('prospectively', 0.681914210319519), ('additionally', 0.6759320497512817), ('part', 0.6713032722473145), ('well', 0.6700907349586487), ('further', 0.6696865558624268), ('financially_operationally', 0.6629063487052917), ('additional', 0.6541106700897217), ('conventionally', 0.6517847180366516)]\n",
      "\n",
      "worker\n",
      "[('worker', 0.8236281871795654), ('employee', 0.7396843433380127), ('salaried_worker', 0.7279316186904907), ('employer', 0.7172468304634094), ('salaried_employee', 0.7097141742706299), ('staff', 0.7082841396331787), ('enroll_worker', 0.7034059166908264), ('paycheck_paycheck', 0.6879183650016785), ('unskilled_worker', 0.6870248317718506), ('employer_dangle', 0.6847037672996521)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/qara/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_s2s)):\n",
    "    print(top_news.lemmatized[index][i])\n",
    "    print(embedding.similar_by_vector(test_s2s[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "test_s2s = generate_seq2seq(total_data.lemmatized[index], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['president', 'obama', 'want', 'give', 'young', 'leader', 'world', 'tool', 'organize']\n"
     ]
    }
   ],
   "source": [
    "print(total_data.lemmatized[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "president\n",
      "[('insist', 0.8229811787605286), ('invite', 0.7954767942428589), ('remind', 0.7830241322517395), ('press', 0.7742473483085632), ('contention', 0.7713900804519653), ('businessman', 0.7694128751754761), ('president_obama', 0.7655007839202881), ('politician', 0.758459210395813), ('white_house', 0.758399486541748), ('supporter', 0.7519349455833435)]\n",
      "\n",
      "obama\n",
      "[('obama', 0.8795356154441833), ('politician', 0.8727269172668457), ('president_obama', 0.8588958978652954), ('democratic_congresswoman', 0.8564929962158203), ('politicize', 0.8531311750411987), ('leftist', 0.8449838757514954), ('barack_obama', 0.8448082208633423), ('supporter', 0.8444757461547852), ('liberal', 0.8440057039260864), ('democratic_party', 0.8385233879089355)]\n",
      "\n",
      "want\n",
      "[('matter', 0.8058760762214661), ('argue', 0.7907227277755737), ('insist', 0.7827374935150146), ('question', 0.7740395069122314), ('advocate', 0.7724536657333374), ('indeed', 0.7714610695838928), ('politician', 0.7605513334274292), ('neither', 0.7587474584579468), ('congressionally', 0.7543606758117676), ('contention', 0.7512086629867554)]\n",
      "\n",
      "give\n",
      "[('also', 0.7833001613616943), ('give', 0.7594306468963623), ('still', 0.7552471160888672), ('many', 0.7198550701141357), ('meanwhile', 0.7186512351036072), ('yet', 0.7156146764755249), ('way', 0.7122019529342651), ('reason', 0.7040297985076904), ('appear', 0.6984908580780029), ('instance', 0.6975593566894531)]\n",
      "\n",
      "young\n",
      "[('politician', 0.8230497241020203), ('dream', 0.7984992265701294), ('socialize', 0.7962859272956848), ('metaphorically_reimagine', 0.7912176847457886), ('god', 0.7887533903121948), ('friend', 0.7876911163330078), ('conservative_christian', 0.7868441939353943), ('hate', 0.7837691903114319), ('frist', 0.7831739187240601), ('angry', 0.7821033596992493)]\n",
      "\n",
      "leader\n",
      "[('also', 0.7537490129470825), ('way', 0.7306206226348877), ('still', 0.727556586265564), ('well', 0.7260090112686157), ('rather', 0.7129924297332764), ('back', 0.7105486989021301), ('many', 0.7025952935218811), ('give', 0.6976937651634216), ('bring', 0.6929680109024048), ('come', 0.6895414590835571)]\n",
      "\n",
      "world\n",
      "[('america', 0.7009888887405396), ('nation', 0.6909750699996948), ('country', 0.6861499547958374), ('way', 0.6719719767570496), ('standing', 0.657636284828186), ('together', 0.6511251330375671), ('outside', 0.6477404236793518), ('rest', 0.645248293876648), ('western', 0.6431256532669067), ('rather', 0.6384631991386414)]\n",
      "\n",
      "tool\n",
      "[('interact', 0.7155632972717285), ('customizable', 0.7102218866348267), ('ubiquitous_connectivity', 0.7005586624145508), ('automatically_detect', 0.6978357434272766), ('connect', 0.6898531913757324), ('customize', 0.6878316402435303), ('customizable_bitmojis', 0.6828612089157104), ('design', 0.6818847060203552), ('automatically_brake', 0.6809970736503601), ('seamlessly_collaborate', 0.6742956042289734)]\n",
      "\n",
      "organize\n",
      "[('organize', 0.862571120262146), ('seamlessly_collaborate', 0.7639220356941223), ('socialize', 0.7448117136955261), ('organized', 0.7253450751304626), ('empower', 0.7183119654655457), ('educate', 0.6875593066215515), ('impersonate', 0.6869457364082336), ('family_friend', 0.6831446886062622), ('message', 0.6822259426116943), ('freely_donate', 0.681146502494812)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/qara/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_s2s)):\n",
    "    print(total_data.lemmatized[index][i])\n",
    "    print(embedding.similar_by_vector(test_s2s[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = load_obj('total_data')\n",
    "\n",
    "idx = total_data.groupby(['date'])['score'].transform(max) == total_data['score']\n",
    "top_news = total_data[idx].sort_values(by=['date'])\n",
    "\n",
    "hot_news = total_data[total_data.score>=1000]\n",
    "#common_news = total_data[total_data.score==0]\n",
    "\n",
    "top_news = top_news.reset_index(drop=True)\n",
    "hot_news = hot_news.sort_values(by='date').reset_index(drop=True)\n",
    "#common_news = common_news.sort_values(by='date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_df(df):\n",
    "    x = []\n",
    "    mask = []\n",
    "    for idx, row in df.iterrows():\n",
    "        title = list(row.lemmatized)\n",
    "        title = [x for x in title if len(x)!=1]\n",
    "\n",
    "        k = embedding[title]\n",
    "        x.append(np.pad(k, ((40-len(k),0), (0,0)), 'constant'))\n",
    "        mask.append(np.array([0 for i in range(40-len(k))] + [1 for i in range(len(k))]))\n",
    "        \n",
    "    yield np.array(list(x)), np.array(list(mask))\n",
    "\n",
    "def extract_code(df, bs=0):\n",
    "    codes = []\n",
    "    c=0\n",
    "    if bs==0:\n",
    "        bs = len(df)\n",
    "    for i in range((len(df))//bs):\n",
    "    #for i in range((len(df)+bs-1)//bs):\n",
    "        small_df = df[bs*i:bs*(i+1)]\n",
    "        for x, mask in generate_from_df(small_df):\n",
    "            c += 1\n",
    "            code = sess.run(model.z_mu, feed_dict={\n",
    "                model.x: x, model.mask: mask\n",
    "            })\n",
    "            codes.append(code)\n",
    "\n",
    "            if c*bs%1000==0:\n",
    "                print(c*bs)\n",
    "    codes = np.array(list(codes))\n",
    "    codes = np.reshape(codes, [-1, 4])\n",
    "    return codes\n",
    "\n",
    "def show_embeds(codes):\n",
    "    colors = cm.rainbow(np.linspace(1, 0, len(codes)))\n",
    "    fig, ax = plt.subplots(1, model.n_z - 1, figsize=(size,size/(model.n_z-1)))\n",
    "    x1 = codes[:, 0]\n",
    "    for idx in range(1, model.n_z):\n",
    "        y1 = codes[:, idx]\n",
    "        #ax[idx-1].set_xlim(-0.4, 0.4)\n",
    "        #ax[idx-1].set_ylim(-0.4, 0.4)\n",
    "        ax[idx-1].scatter(x1, y1, color=colors, s=5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "top_codes = extract_code(top_news,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x240 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_embeds(top_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
