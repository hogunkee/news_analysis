{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'masseswhy analyst say intel mobileye deal be defensive drive'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.utils import lemmatize\n",
    "def clean(text):\n",
    "    text = strip_multiple_whitespaces(strip_non_alphanum(text)).split()\n",
    "    words = []\n",
    "    for word in text:\n",
    "        tmp = lemmatize(word)\n",
    "        if tmp:\n",
    "            words.append(tmp[0][:-3].decode(\"utf-8\"))\n",
    "    return \" \".join(words)\n",
    "\n",
    "tokenize(\"The MassesWhy Analysts Say Intel's Mobileye Deal Is 'Defensive' Driving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[b'masseswhy/NN']\n",
      "[b'analyst/NN']\n",
      "[b'say/VB']\n",
      "[b'intel/NN']\n",
      "[b'mobileye/NN']\n",
      "[b'deal/NN']\n",
      "[b'be/VB']\n",
      "[b'defensive/NN']\n",
      "[b'drive/VB']\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import lemmatize\n",
    "for i in \"The MassesWhy Analysts Say Intel's Mobileye Deal Is 'Defensive' Driving\".split():\n",
    "    print(lemmatize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"news/A.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.13617515563965"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "df['content'].apply(clean)\n",
    "end = time.time()\n",
    "\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1675"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dbin6\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phraser_default.bin  loaded\n"
     ]
    }
   ],
   "source": [
    "import phraser as ph\n",
    "from preprocessing import clean\n",
    "p = ph.PhraserModel().get_phraser\n",
    "text=\"\"\"\n",
    "share abm industry inc abm free report lose industry growth year moreover facility management provider share tumble week low trading session figure re-cover marginally close reason plungeabm industry operate highly competitive industry barrier entry low make difficult company maintain strong long term relationship client order win new client retain exist one company remain technologically update meet vary rapidly change client demand increase operating expense company reduce margin operating expense rise jan figure rise operating cost major headwind company growth company business outside united states especially united kingdom remain susceptible outcome brexit exit european union eu european economy highly unpredictable disruption restriction acquisition trade european union member such activity weigh company revenue margin abm industry highly leveraged balance sheet notably long term debt rise end company cash cash equivalent jan cash cash equivalent long term debt imply industry currently unable generate adequate operating cash flow service debt stock considersome better ranked stock broader business service sector include accenture plc acn free report nv global nvee free report bureau verita bvrdf free report stock carry zack rank buy long term expect earning share growth rate accenture nv global bureau verita respectively today stock zack hottest strategiesit hard believe zack market gain stock pick screen return outperformance recent phenomenon year remarkably consistent composite yearly average gain strategy beat market maybe remarkable fact willing share latest stock cost obligation see free\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abm',\n",
       " 'abm_industry',\n",
       " 'accenture',\n",
       " 'accenture_plc',\n",
       " 'acn',\n",
       " 'acquisition',\n",
       " 'activity',\n",
       " 'adequate',\n",
       " 'average',\n",
       " 'balance_sheet',\n",
       " 'barrier_entry',\n",
       " 'beat',\n",
       " 'brexit',\n",
       " 'broader',\n",
       " 'bureau_verita',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'bvrdf',\n",
       " 'carry',\n",
       " 'cash',\n",
       " 'cash_equivalent',\n",
       " 'cash_flow',\n",
       " 'change',\n",
       " 'client',\n",
       " 'close',\n",
       " 'company',\n",
       " 'composite_yearly',\n",
       " 'considersome_better',\n",
       " 'cost',\n",
       " 'cost_obligation',\n",
       " 'currently',\n",
       " 'debt',\n",
       " 'demand',\n",
       " 'difficult',\n",
       " 'disruption',\n",
       " 'earning',\n",
       " 'economy',\n",
       " 'end',\n",
       " 'especially',\n",
       " 'eu',\n",
       " 'european',\n",
       " 'european_union',\n",
       " 'exist_one',\n",
       " 'exit',\n",
       " 'expect',\n",
       " 'expense',\n",
       " 'facility',\n",
       " 'fact',\n",
       " 'figure',\n",
       " 'free',\n",
       " 'gain',\n",
       " 'generate',\n",
       " 'global',\n",
       " 'global_nvee',\n",
       " 'growth',\n",
       " 'hard_believe',\n",
       " 'headwind',\n",
       " 'highly',\n",
       " 'highly_competitive',\n",
       " 'hottest_strategiesit',\n",
       " 'imply',\n",
       " 'inc',\n",
       " 'include',\n",
       " 'increase',\n",
       " 'industry',\n",
       " 'jan',\n",
       " 'kingdom',\n",
       " 'latest',\n",
       " 'leveraged',\n",
       " 'long_term',\n",
       " 'lose',\n",
       " 'low',\n",
       " 'maintain',\n",
       " 'major',\n",
       " 'make',\n",
       " 'management',\n",
       " 'margin',\n",
       " 'marginally',\n",
       " 'market',\n",
       " 'maybe',\n",
       " 'meet',\n",
       " 'member',\n",
       " 'moreover',\n",
       " 'new',\n",
       " 'notably',\n",
       " 'nv',\n",
       " 'operate',\n",
       " 'operating',\n",
       " 'order',\n",
       " 'outcome',\n",
       " 'outside',\n",
       " 'pick_screen',\n",
       " 'plungeabm',\n",
       " 'provider',\n",
       " 'rank',\n",
       " 'ranked',\n",
       " 'rapidly',\n",
       " 'rate',\n",
       " 're-cover',\n",
       " 'reason',\n",
       " 'recent_phenomenon',\n",
       " 'reduce',\n",
       " 'relationship',\n",
       " 'remain',\n",
       " 'remarkable',\n",
       " 'remarkably_consistent',\n",
       " 'report',\n",
       " 'respectively',\n",
       " 'restriction',\n",
       " 'retain',\n",
       " 'return_outperformance',\n",
       " 'revenue',\n",
       " 'rise',\n",
       " 'sector',\n",
       " 'see',\n",
       " 'service',\n",
       " 'session',\n",
       " 'share',\n",
       " 'states',\n",
       " 'stock',\n",
       " 'strategy',\n",
       " 'strong',\n",
       " 'such',\n",
       " 'susceptible',\n",
       " 'technologically_update',\n",
       " 'today',\n",
       " 'trade',\n",
       " 'trading',\n",
       " 'tumble',\n",
       " 'unable',\n",
       " 'united',\n",
       " 'unpredictable',\n",
       " 'vary',\n",
       " 'week',\n",
       " 'weigh',\n",
       " 'willing',\n",
       " 'win',\n",
       " 'year',\n",
       " 'zack'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ph.tokenizer([text])\n",
    "set([i for i in p[t]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword dictionary loaded\n"
     ]
    }
   ],
   "source": [
    "import dictionary as d\n",
    "zzz = d.KeywordDict(phraser=p).get_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deep_learn\n",
      "234356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7413"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(zzz[7413])\n",
    "print(len(zzz))\n",
    "zzz.token2id['deep_learn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model default loaded\n"
     ]
    }
   ],
   "source": [
    "import tfidf as tf\n",
    "\n",
    "mm = tf.Model(dic=zzz, phraser=p).get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = mm[zzz.doc2bow([token for token in p[text.split()]])]\n",
    "sorted([(zzz[word],score) for word,score in vec], key=lambda x: x[1], reverse=True)\n",
    "\"a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model vpn loaded\n"
     ]
    }
   ],
   "source": [
    "mm = tf.Model(dic=zzz, name='vpn', smartirs='vpn',phraser=p).get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nvidia', 476),\n",
       " ('esp', 123),\n",
       " ('ai', 118),\n",
       " ('self_drive', 112),\n",
       " ('intel', 110),\n",
       " ('semiconductor', 103),\n",
       " ('relative_strength', 95),\n",
       " ('monolithic_power', 95),\n",
       " ('chip', 93),\n",
       " ('gaap', 92),\n",
       " ('system_mpwr', 89),\n",
       " ('rs_rating', 85),\n",
       " ('fabless', 83),\n",
       " ('tesla', 77),\n",
       " ('amd', 75),\n",
       " ('bitcoin', 72),\n",
       " ('etf', 71),\n",
       " ('apple', 68),\n",
       " ('gaming', 68),\n",
       " ('etfs', 64),\n",
       " ('apply_material', 61),\n",
       " ('datum_center', 58),\n",
       " ('fund', 56),\n",
       " ('car', 56),\n",
       " ('netapp', 54),\n",
       " ('entry', 53),\n",
       " ('ttm', 52),\n",
       " ('broadcom', 49),\n",
       " ('gpu', 49),\n",
       " ('micron', 45),\n",
       " ('facebook', 43),\n",
       " ('mobileye', 40),\n",
       " ('nvda', 39),\n",
       " ('sequentially', 39),\n",
       " ('cloud', 38),\n",
       " ('automotive', 37),\n",
       " ('ce', 37),\n",
       " ('artificial_intelligence', 36),\n",
       " ('industry_newsibd', 36),\n",
       " ('texas_instrument', 36),\n",
       " ('zack', 36),\n",
       " ('cryptocurrency', 35),\n",
       " ('industry_newswhich', 35),\n",
       " ('need_know', 35),\n",
       " ('autonomous_vehicle', 35),\n",
       " ('flat_base', 34),\n",
       " ('iot', 33),\n",
       " ('autonomous_drive', 32),\n",
       " ('gpus', 31),\n",
       " ('spdr', 31)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import extractor as ex\n",
    "\n",
    "k = ex.Extractor(mm, zzz, p).extract(\"NVDA\", topn1=10, topn2=50)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding not exists\n",
      "start building...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8ccd9440d4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbbbbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphraser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\dbin6\\PycharmProjects\\work\\redo\\embedding.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, phraser)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding not exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start building...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\dbin6\\PycharmProjects\\work\\redo\\embedding.py\u001b[0m in \u001b[0;36mbuild_embedding\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_cleaned_news\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mtokenized_docs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphraser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\dbin6\\PycharmProjects\\work\\redo\\embedding.py\u001b[0m in \u001b[0;36mtokenizer\u001b[0;34m(corpus, phraser)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mphraser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mtokenized\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphraser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtokenized\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import embedding as em\n",
    "bbbbb = em.EmbeddingModel(phraser=p).get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
