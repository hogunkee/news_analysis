{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim import fully_connected as fc\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "from ThemeSeacher import Updator, clean, PhraserModel, tokenizer\n",
    "from ThemeSeacher import KeywordDict, Model, Extractor\n",
    "from ThemeSeacher import EmbeddingModel, Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phraser_default.bin  loaded\n",
      "keyword dictionary loaded\n"
     ]
    }
   ],
   "source": [
    "phraser = PhraserModel().get_phraser\n",
    "dic = KeywordDict(phraser=phraser).get_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open('obj/' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def exist(name):\n",
    "    return os.path.exists('obj/' + name + '.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding default loaded\n"
     ]
    }
   ],
   "source": [
    "embedding = EmbeddingModel().get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = load_obj('upper1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     [president, obama, want, give, young, leader, ...\n",
       "3             [japan, ask, condemn, korea, rights_abus]\n",
       "11    [ukraine, blame, russia, fatal, ambush, husban...\n",
       "13    [kim_jong_nam, murder, china, break, north, ko...\n",
       "16    [finland, take, phone, call, find, much, neigh...\n",
       "Name: lemmatized, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.lemmatized[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = total_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "for idx, row in total_data.iterrows():\n",
    "    title = list(row.lemmatized)\n",
    "    title = [x for x in title if len(x)!=1]\n",
    "        \n",
    "    train_data.append(embedding[title])\n",
    "    if (idx+1)%100000==0:\n",
    "        print(idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(train_data, 'seq2seq_embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_obj('seq2seq_embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557440"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, bs):\n",
    "    np.random.shuffle(data)\n",
    "    for i in range(len(data)//bs):\n",
    "        batch = data[bs*i: bs*(i+1)]\n",
    "\n",
    "        x_gen = list(map(lambda k: np.pad(k, \\\n",
    "                ((40-len(k),0),(0,0)),'constant'), batch))\n",
    "        mask_gen = list(map(lambda k: np.array(\\\n",
    "                [0 for i in range(40-len(k))] + \\\n",
    "                [1 for j in range(len(k))]), batch))\n",
    "\n",
    "        yield np.array(list(x_gen)), np.array(list(mask_gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnnmodel(object):\n",
    "    def __init__(self, lr=1e-4):\n",
    "        title_len = 40\n",
    "        em_dim = 100\n",
    "        hidden_dim = 100\n",
    "        beta = 1e-5\n",
    "    \n",
    "        self.x = tf.placeholder(tf.float32, [None, title_len, em_dim])\n",
    "        self.mask = tf.placeholder(tf.float32, [None, title_len])\n",
    "        \n",
    "        encoder_cell = tf.contrib.rnn.LSTMCell(hidden_dim)\n",
    "        encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "            encoder_cell, self.x,\n",
    "            dtype=tf.float32, time_major=False,\n",
    "        )\n",
    "        \n",
    "        self.code = encoder_final_state[1]\n",
    "        code = tf.reshape(self.code, [-1, 1, hidden_dim])\n",
    "        print('encoder final state:', encoder_final_state[1])\n",
    "        print('code:', code)\n",
    "        print(self.x)\n",
    "        print(tf.tile(code, [1, title_len, 1]))\n",
    "        print(encoder_final_state)\n",
    "        \n",
    "        decoder_cell = tf.contrib.rnn.LSTMCell(em_dim)\n",
    "        decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "            decoder_cell, tf.tile(code, [1, title_len, 1]),\n",
    "            initial_state = encoder_final_state,\n",
    "            dtype=tf.float32, time_major=False, scope=\"plain_decoder\",\n",
    "        )\n",
    "        print('decoder')\n",
    "        \n",
    "        x_ = tf.reverse(decoder_outputs, [1])\n",
    "        l2_loss = tf.reduce_mean(tf.squared_difference(self.x, x_), axis=2)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(l2_loss * self.mask)\n",
    "        self.train = tf.train.AdamOptimizer(learning_rate=lr).minimize(self.loss)\n",
    "        self.output = x_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder final state: Tensor(\"g1/rnn/while/Exit_4:0\", shape=(?, 100), dtype=float32)\n",
      "code: Tensor(\"g1/Reshape:0\", shape=(?, 1, 100), dtype=float32)\n",
      "Tensor(\"g1/Placeholder:0\", shape=(?, 40, 100), dtype=float32)\n",
      "Tensor(\"g1/Tile:0\", shape=(?, 40, 100), dtype=float32)\n",
      "LSTMStateTuple(c=<tf.Tensor 'g1/rnn/while/Exit_3:0' shape=(?, 100) dtype=float32>, h=<tf.Tensor 'g1/rnn/while/Exit_4:0' shape=(?, 100) dtype=float32>)\n",
      "decoder\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default() as g:\n",
    "    with g.name_scope('g1') as scope:\n",
    "        model = rnnmodel(lr=1e-2)\n",
    "\n",
    "        tfconfig = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "        sess=tf.Session(config=tfconfig)\n",
    "        sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "100 0.012637195\n",
      "200 0.01183142\n",
      "300 0.011044705\n",
      "400 0.010863708\n",
      "500 0.010469265\n",
      "2\n",
      "100 0.01078619\n",
      "200 0.009567589\n",
      "300 0.009628285\n",
      "400 0.010404469\n",
      "500 0.009667555\n",
      "3\n",
      "100 0.010611333\n",
      "200 0.009885514\n",
      "300 0.009893315\n",
      "400 0.009990467\n",
      "500 0.009637642\n",
      "4\n",
      "100 0.00978215\n",
      "200 0.009817317\n",
      "300 0.009984107\n",
      "400 0.009653988\n",
      "500 0.009857389\n",
      "5\n",
      "100 0.009786381\n",
      "200 0.0094190985\n",
      "300 0.009666117\n",
      "400 0.0094984425\n",
      "500 0.009815341\n"
     ]
    }
   ],
   "source": [
    "bs=1000\n",
    "num_steps=len(train_data)//bs\n",
    "ne=5\n",
    "print_step=100\n",
    "for epoch in range(ne):\n",
    "    print('Epoch: [%d]' %(epoch+1))\n",
    "    count = 0\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for batch in generator(train_data, bs):\n",
    "        loss, _ = sess.run([model.loss, model.train], \\\n",
    "                feed_dict={model.x: batch[0], model.mask: batch[1]})\n",
    "        \n",
    "        avg_loss += loss\n",
    "        if (count+1)%print_step==0:\n",
    "            print('steps:', count+1, 'loss-', avg_loss/bs)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_2d(object):\n",
    "\n",
    "    def __init__(self, n_z=2, learning_rate=1e-3, beta=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_z = n_z\n",
    "        self.beta = beta\n",
    "\n",
    "        self.build()\n",
    "        \n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Build the netowrk and the loss functions\n",
    "    def build(self):\n",
    "        self.x = tf.placeholder(name='x', dtype=tf.float32, shape=[None, 100])\n",
    "\n",
    "        # Encode\n",
    "        # x -> z_mean, z_sigma -> z\n",
    "        f1 = fc(self.x, 100, scope='enc_fc1', activation_fn=tf.nn.elu)\n",
    "        f2 = fc(f1, 64, scope='enc_fc2', activation_fn=tf.nn.elu)\n",
    "        f3 = fc(f2, 64, scope='enc_fc3', activation_fn=tf.nn.elu)\n",
    "        f4 = fc(f3, 32, scope='enc_fc4', activation_fn=tf.nn.elu)\n",
    "        f5 = fc(f4, 32, scope='enc_fc5', activation_fn=tf.nn.elu)\n",
    "        f6 = fc(f5, 16, scope='enc_fc6', activation_fn=tf.nn.elu)\n",
    "        f7 = fc(f6, 16, scope='enc_fc7', activation_fn=tf.nn.elu)\n",
    "        f8 = fc(f7, 8, scope='enc_fc8', activation_fn=tf.nn.elu)\n",
    "        f9 = fc(f8, 8, scope='enc_fc9', activation_fn=tf.nn.elu)\n",
    "        f10 = fc(f9, 4, scope='enc_fc10', activation_fn=tf.nn.elu)\n",
    "        self.z_mu = fc(f10, self.n_z, scope='enc_fc11_mu', activation_fn=None)\n",
    "        self.z_log_sigma_sq = fc(f10, self.n_z, scope='enc_fc11_sigma', activation_fn=None)\n",
    "        eps = tf.random_normal(shape=tf.shape(self.z_log_sigma_sq),\n",
    "                               mean=0, stddev=0.001, dtype=tf.float32)\n",
    "        self.z = self.z_mu + tf.sqrt(tf.exp(self.z_log_sigma_sq)) * eps\n",
    "\n",
    "        # Decode\n",
    "        # z -> x_hat\n",
    "        g1 = fc(self.z, 4, scope='dec_fc1', activation_fn=tf.nn.elu)\n",
    "        g2 = fc(g1, 8, scope='dec_fc2', activation_fn=tf.nn.elu)\n",
    "        g3 = fc(g2, 8, scope='dec_fc3', activation_fn=tf.nn.elu)\n",
    "        g4 = fc(g3, 16, scope='dec_fc4', activation_fn=tf.nn.elu)\n",
    "        g5 = fc(g4, 16, scope='dec_fc5', activation_fn=tf.nn.elu)\n",
    "        g6 = fc(g5, 32, scope='dec_fc6', activation_fn=tf.nn.elu)\n",
    "        g7 = fc(g6, 32, scope='dec_fc7', activation_fn=tf.nn.elu)\n",
    "        g8 = fc(g7, 64, scope='dec_fc8', activation_fn=tf.nn.elu)\n",
    "        g9 = fc(g8, 64, scope='dec_fc9', activation_fn=tf.nn.elu)\n",
    "        g10 = fc(g9, 100, scope='dec_fc10', activation_fn=tf.nn.elu)\n",
    "        self.x_hat = fc(g10, 100, scope='dec_fc11', activation_fn=None)\n",
    "\n",
    "        # Loss\n",
    "        # Reconstruction loss\n",
    "        # Minimize the cross-entropy loss\n",
    "        # H(x, x_hat) = -\\Sigma x*log(x_hat) + (1-x)*log(1-x_hat)\n",
    "        epsilon = 1e-10\n",
    "        #'''\n",
    "        recon_loss = tf.reduce_mean(tf.squared_difference(self.x_hat, self.x))\n",
    "        '''\n",
    "        recon_loss = -tf.reduce_sum(\n",
    "            self.x * tf.log(epsilon+self.x_hat) + (1-self.x) * tf.log(epsilon+1-self.x_hat),\n",
    "            axis=1\n",
    "        )\n",
    "        #'''\n",
    "        self.recon_loss = tf.reduce_mean(recon_loss)\n",
    "\n",
    "        # Latent loss\n",
    "        # Kullback Leibler divergence: measure the difference between two distributions\n",
    "        # Here we measure the divergence between the latent distribution and N(0, 1)\n",
    "        latent_loss = -0.5 * tf.reduce_sum(\n",
    "            1 + self.z_log_sigma_sq - tf.square(self.z_mu) - tf.exp(self.z_log_sigma_sq), axis=1)\n",
    "        self.latent_loss = tf.reduce_mean(latent_loss)\n",
    "\n",
    "        self.total_loss = tf.reduce_mean(recon_loss + self.beta * latent_loss)\n",
    "        self.train_op = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate).minimize(self.total_loss)\n",
    "        return\n",
    "\n",
    "    # Execute the forward and the backward pass\n",
    "    def run_single_step(self, x):\n",
    "        _, loss, recon_loss, latent_loss = self.sess.run(\n",
    "            [self.train_op, self.total_loss, self.recon_loss, self.latent_loss],\n",
    "            feed_dict={self.x: x}\n",
    "        )\n",
    "        return loss, recon_loss, latent_loss\n",
    "\n",
    "    # x -> x_hat\n",
    "    def reconstructor(self, x):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.x: x})\n",
    "        return x_hat\n",
    "\n",
    "    # z -> x\n",
    "    def generator(self, z):\n",
    "        x_hat = self.sess.run(self.x_hat, feed_dict={self.z: z})\n",
    "        return x_hat\n",
    "\n",
    "    # x -> z\n",
    "    def transformer(self, x):\n",
    "        z = self.sess.run(self.z, feed_dict={self.x: x})\n",
    "        return z\n",
    "    \n",
    "    def restore(self, saver, ckpt):\n",
    "        saver.restore(self.sess, ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/final/mg2_200.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "model_name = 'final/mg2_200'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default() as g:\n",
    "    #with g.name_scope('g2') as scope:\n",
    "    vae_model = VAE_2d(n_z=4, learning_rate=1e-4, beta=0.01)\n",
    "    saver = tf.train.Saver()\n",
    "    vae_model.restore(saver, './ckpt/%s.ckpt' %model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vae(word_list, model):\n",
    "    title = [x for x in word_list if len(x)!=1]\n",
    "    embed = embedding[title]\n",
    "    x = np.pad(embed, ((40-len(embed),0), (0,0)), 'constant')\n",
    "    mask = np.array([0 for i in range(40-len(embed))] + [1 for i in range(len(embed))])\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    tfconfig = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "    #with tf.Session(graph=g1, config=tfconfig) as sess:\n",
    "    code = sess.run(model.code, feed_dict={model.x: [np.array(list(x))], \\\n",
    "                       model.mask: [np.array(list(mask))]})\n",
    "    \n",
    "    code_recon = vae_model.reconstructor(code)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    #with tf.Session(graph=g1, config=tfconfig) as sess:\n",
    "    output = sess.run(model.output, feed_dict={model.x: [np.array(list(x))], \\\n",
    "           model.mask: [np.array(list(mask))], model.code: code_recon})\n",
    "    return output[0][-len(embed):]\n",
    "\n",
    "def generate_seq2seq(word_list, model):\n",
    "    title = [x for x in word_list if len(x)!=1]\n",
    "    embed = embedding[title]\n",
    "    x = np.pad(embed, ((40-len(embed),0), (0,0)), 'constant')\n",
    "    mask = np.array([0 for i in range(40-len(embed))] + [1 for i in range(len(embed))])\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    output = sess.run(model.output, feed_dict={model.x: [np.array(list(x))], \\\n",
    "                       model.mask: [np.array(list(mask))]})\n",
    "    \n",
    "    return output[0][-len(embed):]\n",
    "\n",
    "def code_extraction(word_list, model):\n",
    "    title = [x for x in word_list if len(x)!=1]\n",
    "    embed = embedding[title]\n",
    "    x = np.pad(embed, ((40-len(embed),0), (0,0)), 'constant')\n",
    "    mask = np.array([0 for i in range(40-len(embed))] + [1 for i in range(len(embed))])\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    tfconfig = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "    \n",
    "    code = sess.run(model.code, feed_dict={model.x: [np.array(list(x))], \\\n",
    "                       model.mask: [np.array(list(mask))]})\n",
    "    \n",
    "    code_recon = vae_model.reconstructor(code)\n",
    "    \n",
    "    return code, code_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "test_vae = generate_vae(total_data.lemmatized[1], model)\n",
    "test_s2s = generate_seq2seq(total_data.lemmatized[1], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.20027529, -0.13018477,  0.03980954,  0.21736607,  0.02524574,\n",
       "         -0.02402929, -0.28230315,  0.09049254, -0.13874799, -0.09714895,\n",
       "          0.02653462,  0.0269086 , -0.33080766,  0.5275354 ,  0.21938805,\n",
       "          0.30270538,  0.14878947,  0.15191437, -0.2992179 , -0.00331125,\n",
       "         -0.2815965 ,  0.11543564,  0.01201137,  0.03026124,  0.11828549,\n",
       "         -0.32321078, -0.03908052, -0.08149406, -0.3764791 ,  0.22746891,\n",
       "          0.03820552, -0.10167433,  0.05854119, -0.05453959,  0.12319708,\n",
       "         -0.25092563, -0.06562562, -0.00290043,  0.11651237,  0.15291126,\n",
       "         -0.02640409, -0.09764643,  0.14780325,  0.09023331,  0.06406042,\n",
       "          0.08276749,  0.16384453, -0.00955445, -0.01579162, -0.23494753,\n",
       "          0.0509443 ,  0.09332494,  0.15396006, -0.11410368, -0.25492015,\n",
       "         -0.03342448, -0.10541394, -0.18522108,  0.0407915 ,  0.24781626,\n",
       "          0.01616971,  0.06525198,  0.14882937, -0.27299055, -0.16267157,\n",
       "          0.11947787,  0.3307075 , -0.28442934,  0.11285283, -0.02695539,\n",
       "          0.00958274,  0.12930275,  0.25243935,  0.02473719,  0.01318582,\n",
       "          0.3308617 , -0.03254037, -0.24316339, -0.15070935,  0.46210834,\n",
       "          0.12461884, -0.0455449 ,  0.0716041 , -0.33155203, -0.27968633,\n",
       "         -0.14583969,  0.19450663,  0.3666365 ,  0.17085432, -0.04604047,\n",
       "         -0.14021255, -0.03947027, -0.04886303,  0.16332963,  0.20050037,\n",
       "         -0.00741448,  0.5462027 , -0.05749049, -0.26245928,  0.24577735]],\n",
       "       dtype=float32),\n",
       " array([[-0.05362248, -0.00239107, -0.12498241,  0.22071576, -0.19740921,\n",
       "         -0.08755611, -0.26577067,  0.02828111, -0.36452505,  0.06119188,\n",
       "          0.09688675, -0.04063267,  0.01464711,  0.04156501, -0.0699011 ,\n",
       "          0.18872644,  0.1073781 , -0.12471595, -0.01383458,  0.13327663,\n",
       "         -0.17280102,  0.04338625, -0.06070396,  0.00682466,  0.18206808,\n",
       "          0.05531038, -0.13164082,  0.01935294, -0.00683974, -0.00140295,\n",
       "          0.0627738 , -0.18587838, -0.01175009,  0.0190046 , -0.07578994,\n",
       "         -0.14192507, -0.04384175,  0.10621788,  0.1988921 , -0.11809166,\n",
       "         -0.23426577,  0.18738982,  0.36858067, -0.16708148, -0.15128538,\n",
       "         -0.20707445, -0.02306755,  0.06848474,  0.03939889, -0.0580243 ,\n",
       "          0.03996818, -0.16786587,  0.11936972, -0.07412393,  0.02066437,\n",
       "          0.0335886 ,  0.01583997, -0.13990813,  0.03438678,  0.13553387,\n",
       "          0.05233596,  0.31621882,  0.21860522, -0.22922887, -0.05749834,\n",
       "         -0.04269396, -0.06341261, -0.00752626, -0.17788042, -0.00528576,\n",
       "          0.02460223,  0.00294932, -0.06354345,  0.16113566, -0.13837586,\n",
       "          0.20479631, -0.07327145, -0.23669764,  0.09492718,  0.05213217,\n",
       "         -0.15291086, -0.12757437, -0.07948507, -0.06053536, -0.18469179,\n",
       "          0.09891826,  0.0147631 ,  0.10510228,  0.04188788,  0.11258902,\n",
       "         -0.14290753,  0.01808009, -0.17849201,  0.03190831,  0.32227898,\n",
       "          0.20504087,  0.15552014,  0.05139424, -0.29643214,  0.1502731 ]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_extraction(total_data.lemmatized[1], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['president', 'obama', 'want', 'give', 'young', 'leader', 'world', 'tool', 'organize']\n"
     ]
    }
   ],
   "source": [
    "print(total_data.lemmatized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('abc_cancele', 0.5616289377212524), ('film_coco', 0.5578174591064453), ('sep_downcast', 0.5497655868530273), ('flu', 0.5437222719192505), ('fatigue_pain', 0.5226050615310669), ('barr_debacle', 0.52010178565979), ('include_pyelonephritis', 0.515978217124939), ('kidney_liver', 0.5144096612930298), ('nonsteroidal_inflammatory', 0.5140340328216553), ('severe_anemia', 0.5129023790359497)]\n",
      "\n",
      "[('sep_downcast', 0.5242416262626648), ('hurricane_nate', 0.5188075304031372), ('abc_cancele', 0.5171298980712891), ('hurricane_impactlayoff', 0.5166088342666626), ('severe_anemia', 0.5149905681610107), ('effect_concomitant', 0.5131708979606628), ('dbrs_fake', 0.5089902877807617), ('stamo_tweet', 0.5051372051239014), ('reveal_resentation', 0.5012757778167725), ('allegedly_exorbitant', 0.5009552240371704)]\n",
      "\n",
      "[('fallout', 0.5692722797393799), ('wo_insufficient', 0.5444861650466919), ('affected_barrage', 0.5437876582145691), ('unexpected_complication', 0.5355677604675293), ('spike', 0.5228429436683655), ('due', 0.5190272331237793), ('plan_overburden', 0.5148128867149353), ('uncertainty_revolve', 0.5147379636764526), ('creditwatch_negative', 0.5132178068161011), ('widespread', 0.5087076425552368)]\n",
      "\n",
      "[('mixed_bag', 0.5647560358047485), ('due', 0.5566927790641785), ('partly_due', 0.5518847703933716), ('dampen', 0.5406587719917297), ('wo_insufficient', 0.532906711101532), ('creditwatch_negative', 0.5324421525001526), ('introduction_softening', 0.5215332508087158), ('uncertainty', 0.5214630961418152), ('fallout', 0.5212280750274658), ('wo', 0.5211427211761475)]\n",
      "\n",
      "[('dampenersone', 0.5477724671363831), ('partly_due', 0.5427658557891846), ('benefit_renewlife', 0.5256519913673401), ('due', 0.525502622127533), ('benefita', 0.5220010876655579), ('dampen', 0.5052582025527954), ('weak', 0.5044873356819153), ('earthquake_rocked', 0.5036759376525879), ('flagship', 0.4966556131839752), ('adversely_impact', 0.4962809681892395)]\n",
      "\n",
      "[('benefit_renewlife', 0.5249252915382385), ('benefita', 0.5229647159576416), ('pacific_apac', 0.5089436173439026), ('italy_saes', 0.5050235986709595), ('caico_irma', 0.5049980282783508), ('northeast_midwest', 0.49853628873825073), ('season_xep', 0.49542155861854553), ('southeast_midwest', 0.4909152686595917), ('cycl', 0.4896077513694763), ('libre_internationally', 0.4892294406890869)]\n",
      "\n",
      "[('season_xep', 0.5131101012229919), ('club_aaa', 0.5039833784103394), ('canada_costa', 0.5034136772155762), ('canada_cemea', 0.493225634098053), ('pacific_latin', 0.488351970911026), ('pacific_apac', 0.4818670153617859), ('canada_colombia', 0.4799794554710388), ('pacific_lpx', 0.4780210554599762), ('benefitin', 0.47504279017448425), ('club_cuervos', 0.4742979407310486)]\n",
      "\n",
      "[('tap', 0.45799869298934937), ('faltered_speculation', 0.44531378149986267), ('rolled_bevy', 0.4446272850036621), ('introduction_softening', 0.442656546831131), ('wpp_wppgy', 0.4377825856208801), ('prereleased', 0.43589645624160767), ('effortin_notable', 0.43482068181037903), ('digital_smac', 0.43436381220817566), ('sell_xalso', 0.4332255721092224), ('slew', 0.43107110261917114)]\n",
      "\n",
      "[('office_comptroller', 0.5587481260299683), ('comptroller', 0.5498694777488708), ('comptroller_bush', 0.5360202193260193), ('comptroller_scott', 0.528479278087616), ('comptroller_currency', 0.5276895761489868), ('virtually_unanimous', 0.5229500532150269), ('documentary_anderman', 0.5167424082756042), ('sudden_resignation', 0.5119936466217041), ('commissioner_g√ºnther', 0.5104507207870483), ('occ', 0.5095364451408386)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "  \n",
      "/home/qara/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_gen)):\n",
    "    print(embedding.similar_by_vector(test_vae[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('insist', 0.7841520309448242), ('president_obama', 0.7695669531822205), ('press', 0.7526883482933044), ('supporter', 0.7513612508773804), ('congressionally', 0.7492458820343018), ('invite', 0.7473600506782532), ('openly', 0.7466476559638977), ('democratically_elect', 0.7462288737297058), ('white_house', 0.7457312345504761), ('obama', 0.7449266314506531)]\n",
      "\n",
      "[('obama', 0.8969504237174988), ('president_obama', 0.8721156120300293), ('barack_obama', 0.868120551109314), ('leftist', 0.8426805734634399), ('politician', 0.8405747413635254), ('supporter', 0.8384084701538086), ('democratic_party', 0.836190938949585), ('communist_dictator', 0.8334490656852722), ('democratic_congresswoman', 0.8332608342170715), ('democracy', 0.8316212892532349)]\n",
      "\n",
      "[('convince', 0.7757793664932251), ('matter', 0.7441308498382568), ('explain', 0.740172266960144), ('question', 0.7266321182250977), ('neither', 0.7199560403823853), ('decide', 0.7144235372543335), ('ask', 0.7121338844299316), ('indeed', 0.7078919410705566), ('remind', 0.7041139602661133), ('way', 0.7015412449836731)]\n",
      "\n",
      "[('way', 0.7330796122550964), ('give', 0.6944938898086548), ('convince', 0.683925211429596), ('head', 0.6792197227478027), ('rather', 0.6730958819389343), ('bring', 0.6592031121253967), ('do', 0.6575295329093933), ('so', 0.6537805199623108), ('truly', 0.6530993580818176), ('back', 0.6525643467903137)]\n",
      "\n",
      "[('socialist', 0.7944424152374268), ('capitalist', 0.7717198133468628), ('friend', 0.7705861926078796), ('cuban', 0.7669305801391602), ('businessman', 0.7660627365112305), ('america', 0.7655459046363831), ('prosperously', 0.7654190063476562), ('imagine', 0.7652771472930908), ('founding_father', 0.7621074318885803), ('politician', 0.7618018388748169)]\n",
      "\n",
      "[('way', 0.7285851836204529), ('perhaps', 0.7104482650756836), ('hope', 0.7100414037704468), ('certainly', 0.6942267417907715), ('once_again', 0.692538857460022), ('convince', 0.6896543502807617), ('appear', 0.689106822013855), ('especially', 0.6868370771408081), ('again', 0.6852164268493652), ('indeed', 0.6844041347503662)]\n",
      "\n",
      "[('country', 0.7168481349945068), ('nation', 0.7030287981033325), ('way', 0.6811884045600891), ('outside', 0.6808289289474487), ('rather', 0.6796855926513672), ('together', 0.6758612990379333), ('also', 0.6710283756256104), ('america', 0.6700318455696106), ('many', 0.6699945330619812), ('indeed', 0.6623425483703613)]\n",
      "\n",
      "[('tool', 0.6926095485687256), ('customize', 0.682876706123352), ('personalize', 0.6599754095077515), ('used', 0.6559975743293762), ('similarly_seamlessly', 0.6367489695549011), ('tivo_personalize', 0.6366053819656372), ('excel_simultaneously', 0.6360262632369995), ('advertiser_seamlessly', 0.6330729722976685), ('method', 0.6228516697883606), ('design', 0.6218653321266174)]\n",
      "\n",
      "[('organize', 0.8091133832931519), ('invite', 0.7376997470855713), ('socialize', 0.7137491703033447), ('charity', 0.7081030011177063), ('empower', 0.6964589953422546), ('friend', 0.6951165795326233), ('organized', 0.6896961331367493), ('volunteer', 0.6889971494674683), ('recruit', 0.6877875924110413), ('chelsea_clinton', 0.6870242357254028)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qara/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similar_by_vector` (Method will be removed in 4.0.0, use self.wv.similar_by_vector() instead).\n",
      "  \n",
      "/home/qara/anaconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_gen)):\n",
    "    print(embedding.similar_by_vector(test_s2s[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
